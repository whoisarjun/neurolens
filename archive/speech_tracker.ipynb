{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b38507c7",
   "metadata": {},
   "source": [
    "# Dementia Speech Trend Tracker (Hackathon Edition)\n",
    "So this is the quick notebook we smashed together during the hackathon.\n",
    "It yanks features from Whisper text and tries to guess MMSE, MoCA, and CDR.\n",
    "Charts and stuff show how the patient's speech is drifting over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d120fd",
   "metadata": {},
   "source": [
    "## Install deps real quickGrab everything we'll need. Sorry if this takes a sec."
   ]
  },
  {
   "cell_type": "code",
   "id": "186a2107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:28:08.232908Z",
     "start_time": "2025-06-21T17:26:37.548936Z"
    }
   },
   "source": [
    "# quick install, fingers crossed\n",
    "!pip install numpy==1.24.4 nltk spacy benepar textstat gensim scikit-learn matplotlib tqdm sentence-transformers --quiet\n",
    "!python3 -m spacy download en_core_web_sm --quiet\n",
    "!python3 -m benepar.download benepar_en3 --quiet"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "moviepy 2.2.1 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\r\n",
      "torchvision 0.22.0 requires torch==2.7.0, but you have torch 2.6.0 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\u001B[38;5;2mâœ” Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n",
      "/Users/arjunpalakkal/Documents/[01] Personal/[01] Coding Projects/[02] Github Stuff/[01] Graphite/.venv/bin/python3: No module named benepar.download\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "38744252",
   "metadata": {},
   "source": [
    "## Imports and setupAll the usual libraries. It's a bit messy but works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866720b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001B[93mbenepar_en3\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> benepar.download('benepar_en3')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mmodels/benepar_en3\u001B[0m\n\n  Searched in:\n    - '/Users/vincent/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mLookupError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 18\u001B[39m\n\u001B[32m     16\u001B[39m nlp = spacy.load(\u001B[33m'\u001B[39m\u001B[33men_core_web_sm\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m nlp.has_pipe(\u001B[33m'\u001B[39m\u001B[33mbenepar\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m     \u001B[43mnlp\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd_pipe\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mbenepar\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mbenepar_en3\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m sentence_model = SentenceTransformer(\u001B[33m'\u001B[39m\u001B[33mall-MiniLM-L6-v2\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     22\u001B[39m baseline = {}  \u001B[38;5;66;03m# patient -> feature dict\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/spacy/language.py:825\u001B[39m, in \u001B[36mLanguage.add_pipe\u001B[39m\u001B[34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001B[39m\n\u001B[32m    821\u001B[39m     pipe_component, factory_name = \u001B[38;5;28mself\u001B[39m.create_pipe_from_source(\n\u001B[32m    822\u001B[39m         factory_name, source, name=name\n\u001B[32m    823\u001B[39m     )\n\u001B[32m    824\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m825\u001B[39m     pipe_component = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcreate_pipe\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfactory_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    827\u001B[39m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    828\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    829\u001B[39m \u001B[43m        \u001B[49m\u001B[43mraw_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43mraw_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    830\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    831\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    832\u001B[39m pipe_index = \u001B[38;5;28mself\u001B[39m._get_pipe_index(before, after, first, last)\n\u001B[32m    833\u001B[39m \u001B[38;5;28mself\u001B[39m._pipe_meta[name] = \u001B[38;5;28mself\u001B[39m.get_factory_meta(factory_name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/spacy/language.py:713\u001B[39m, in \u001B[36mLanguage.create_pipe\u001B[39m\u001B[34m(self, factory_name, name, config, raw_config, validate)\u001B[39m\n\u001B[32m    710\u001B[39m cfg = {factory_name: config}\n\u001B[32m    711\u001B[39m \u001B[38;5;66;03m# We're calling the internal _fill here to avoid constructing the\u001B[39;00m\n\u001B[32m    712\u001B[39m \u001B[38;5;66;03m# registered functions twice\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m713\u001B[39m resolved = \u001B[43mregistry\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    714\u001B[39m filled = registry.fill({\u001B[33m\"\u001B[39m\u001B[33mcfg\u001B[39m\u001B[33m\"\u001B[39m: cfg[factory_name]}, validate=validate)[\u001B[33m\"\u001B[39m\u001B[33mcfg\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    715\u001B[39m filled = Config(filled)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/confection/__init__.py:760\u001B[39m, in \u001B[36mregistry.resolve\u001B[39m\u001B[34m(cls, config, schema, overrides, validate)\u001B[39m\n\u001B[32m    751\u001B[39m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[32m    752\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mresolve\u001B[39m(\n\u001B[32m    753\u001B[39m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    758\u001B[39m     validate: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    759\u001B[39m ) -> Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[32m--> \u001B[39m\u001B[32m760\u001B[39m     resolved, _ = \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    761\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema\u001B[49m\u001B[43m=\u001B[49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moverrides\u001B[49m\u001B[43m=\u001B[49m\u001B[43moverrides\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresolve\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[32m    762\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    763\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m resolved\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/confection/__init__.py:809\u001B[39m, in \u001B[36mregistry._make\u001B[39m\u001B[34m(cls, config, schema, overrides, resolve, validate)\u001B[39m\n\u001B[32m    807\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interpolated:\n\u001B[32m    808\u001B[39m     config = Config(orig_config).interpolate()\n\u001B[32m--> \u001B[39m\u001B[32m809\u001B[39m filled, _, resolved = \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fill\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    810\u001B[39m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moverrides\u001B[49m\u001B[43m=\u001B[49m\u001B[43moverrides\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresolve\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresolve\u001B[49m\n\u001B[32m    811\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    812\u001B[39m filled = Config(filled, section_order=section_order)\n\u001B[32m    813\u001B[39m \u001B[38;5;66;03m# Check that overrides didn't include invalid properties not in config\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/confection/__init__.py:881\u001B[39m, in \u001B[36mregistry._fill\u001B[39m\u001B[34m(cls, config, schema, validate, resolve, parent, overrides)\u001B[39m\n\u001B[32m    878\u001B[39m     getter = \u001B[38;5;28mcls\u001B[39m.get(reg_name, func_name)\n\u001B[32m    879\u001B[39m     \u001B[38;5;66;03m# We don't want to try/except this and raise our own error\u001B[39;00m\n\u001B[32m    880\u001B[39m     \u001B[38;5;66;03m# here, because we want the traceback if the function fails.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m881\u001B[39m     getter_result = \u001B[43mgetter\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    882\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    883\u001B[39m     \u001B[38;5;66;03m# We're not resolving and calling the function, so replace\u001B[39;00m\n\u001B[32m    884\u001B[39m     \u001B[38;5;66;03m# the getter_result with a Promise class\u001B[39;00m\n\u001B[32m    885\u001B[39m     getter_result = Promise(\n\u001B[32m    886\u001B[39m         registry=reg_name, name=func_name, args=args, kwargs=kwargs\n\u001B[32m    887\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/benepar/integrations/spacy_plugin.py:176\u001B[39m, in \u001B[36mcreate_benepar_component\u001B[39m\u001B[34m(nlp, name, model, subbatch_max_tokens, disable_tagger)\u001B[39m\n\u001B[32m    169\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate_benepar_component\u001B[39m(\n\u001B[32m    170\u001B[39m     nlp,\n\u001B[32m    171\u001B[39m     name,\n\u001B[32m   (...)\u001B[39m\u001B[32m    174\u001B[39m     disable_tagger: \u001B[38;5;28mbool\u001B[39m,\n\u001B[32m    175\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m176\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mBeneparComponent\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    177\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    178\u001B[39m \u001B[43m        \u001B[49m\u001B[43msubbatch_max_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[43msubbatch_max_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdisable_tagger\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdisable_tagger\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/benepar/integrations/spacy_plugin.py:116\u001B[39m, in \u001B[36mBeneparComponent.__init__\u001B[39m\u001B[34m(self, name, subbatch_max_tokens, disable_tagger, batch_size)\u001B[39m\n\u001B[32m     96\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\n\u001B[32m     97\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m     98\u001B[39m     name,\n\u001B[32m   (...)\u001B[39m\u001B[32m    101\u001B[39m     batch_size=\u001B[33m\"\u001B[39m\u001B[33mignored\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    102\u001B[39m ):\n\u001B[32m    103\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Load a trained parser model.\u001B[39;00m\n\u001B[32m    104\u001B[39m \n\u001B[32m    105\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    114\u001B[39m \u001B[33;03m        batch_size: deprecated and ignored; use subbatch_max_tokens instead\u001B[39;00m\n\u001B[32m    115\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m     \u001B[38;5;28mself\u001B[39m._parser = \u001B[43mload_trained_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    117\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m torch.cuda.is_available():\n\u001B[32m    118\u001B[39m         \u001B[38;5;28mself\u001B[39m._parser.cuda()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/benepar/integrations/downloader.py:32\u001B[39m, in \u001B[36mload_trained_model\u001B[39m\u001B[34m(model_name_or_path)\u001B[39m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_trained_model\u001B[39m(model_name_or_path):\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m     model_path = \u001B[43mlocate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name_or_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     33\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mparse_chart\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChartParser\n\u001B[32m     34\u001B[39m     parser = ChartParser.from_trained(model_path)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/benepar/integrations/downloader.py:27\u001B[39m, in \u001B[36mlocate_model\u001B[39m\u001B[34m(name)\u001B[39m\n\u001B[32m     24\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     25\u001B[39m         arg = e.args[\u001B[32m0\u001B[39m].replace(\u001B[33m\"\u001B[39m\u001B[33mnltk.download\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mbenepar.download\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m(arg)\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mCan\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt find \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m\"\u001B[39m.format(name))\n",
      "\u001B[31mLookupError\u001B[39m: \n**********************************************************************\n  Resource \u001B[93mbenepar_en3\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> benepar.download('benepar_en3')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mmodels/benepar_en3\u001B[0m\n\n  Searched in:\n    - '/Users/vincent/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/share/nltk_data'\n    - '/Library/Frameworks/Python.framework/Versions/3.11/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import spacy\n",
    "import benepar\n",
    "import textstat\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "if not nlp.has_pipe('benepar'):\n",
    "    nlp.add_pipe('benepar', config={'model': 'benepar_en3'})\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "baseline = {}  # patient -> feature dict\n",
    "history = {}   # patient -> list of daily records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce362c",
   "metadata": {},
   "source": [
    "## compute_features (sorry for the long function)Pulls a bunch of things out of a transcript. Works, but could be prettier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197d39f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def compute_features(\n",
    "    transcript_text: str,\n",
    "    duration_sec: float,\n",
    "    segments: Optional[List[Dict[str, Any]]] = None,\n",
    "    baseline_embedding: Optional[np.ndarray] = None,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Compute linguistic features from a transcript.\"\"\"\n",
    "\n",
    "    if segments is None:\n",
    "        segments = []\n",
    "\n",
    "    # --- basic tokenization ---\n",
    "    try:\n",
    "        words = word_tokenize(transcript_text.lower())\n",
    "    except Exception:\n",
    "        words = []\n",
    "    try:\n",
    "        sentences = sent_tokenize(transcript_text)\n",
    "    except Exception:\n",
    "        sentences = []\n",
    "\n",
    "    total_words = len(words)\n",
    "    num_sentences = len(sentences)\n",
    "    unique_words = len(set(words))\n",
    "\n",
    "    # Words spoken per second\n",
    "    speech_speed = total_words / duration_sec if duration_sec > 0 else 0.0\n",
    "\n",
    "    # --- pause statistics ---\n",
    "    marker_pauses = len(re.findall(r\"\\.\\.\\.|<pause>\", transcript_text))\n",
    "    gap_durations = []\n",
    "    for i in range(1, len(segments)):\n",
    "        try:\n",
    "            prev_end = float(segments[i - 1][\"end\"])\n",
    "            start = float(segments[i][\"start\"])\n",
    "            gap = start - prev_end\n",
    "        except Exception:\n",
    "            continue\n",
    "        if gap > 0.3:\n",
    "            gap_durations.append(gap)\n",
    "    num_pauses = marker_pauses + len(gap_durations)\n",
    "    pause_mean = float(np.mean(gap_durations)) if gap_durations else 0.0\n",
    "    pause_var = float(np.var(gap_durations)) if gap_durations else 0.0\n",
    "\n",
    "    # --- vocabulary statistics ---\n",
    "    vocab_richness = unique_words / total_words if total_words > 0 else 0.0\n",
    "    # filler_count = sum(1 for word in words if word in FILLER_WORDS)\n",
    "    # filler_word_rate = filler_count / total_words if total_words > 0 else 0.0\n",
    "    if total_words > 0:\n",
    "        lexical_diversity = textstat.lexicon_count(transcript_text) / total_words\n",
    "    else:\n",
    "        lexical_diversity = 0.0\n",
    "    avg_sentence_length = total_words / num_sentences if num_sentences > 0 else 0.0\n",
    "\n",
    "    # --- syntactic features ---\n",
    "    doc = nlp(transcript_text) if transcript_text.strip() else None\n",
    "    #avg_parse_depth = get_avg_parse_depth(doc) if doc else 0.0 \n",
    "    dep_lengths = []\n",
    "    if doc:\n",
    "        for tok in doc:\n",
    "            if tok.dep_ != \"ROOT\":\n",
    "                dep_lengths.append(abs(tok.i - tok.head.i))\n",
    "    avg_dependency_length = float(np.mean(dep_lengths)) if dep_lengths else 0.0\n",
    "\n",
    "    # --- articulation ---\n",
    "    syllable_count = textstat.syllable_count(transcript_text)\n",
    "    speech_articulation_rate = syllable_count / duration_sec if duration_sec > 0 else 0.0\n",
    "\n",
    "    # --- discourse coherence ---\n",
    "    #coherence_score = compute_coherence_score(transcript_text) \n",
    "\n",
    "    # --- repetition ---\n",
    "    word_counts = Counter(words)\n",
    "    repeated_words = 0\n",
    "    for w, c in word_counts.items():\n",
    "        if c > 1:\n",
    "            repeated_words += 1\n",
    "    repetition_rate = repeated_words / total_words if total_words > 0 else 0.0\n",
    "\n",
    "    # --- pronoun vs noun usage ---\n",
    "    pronoun_count = 0\n",
    "    noun_count = 0\n",
    "    if doc:\n",
    "        for token in doc:\n",
    "            if token.pos_ == \"PRON\":\n",
    "                pronoun_count += 1\n",
    "            elif token.pos_ == \"NOUN\":\n",
    "                noun_count += 1\n",
    "    pronoun_noun_ratio = pronoun_count / noun_count if noun_count > 0 else 0.0\n",
    "\n",
    "    # --- verb tense ratios ---\n",
    "    verbs = []\n",
    "    if doc:\n",
    "        for token in doc:\n",
    "            if token.pos_ in {\"VERB\", \"AUX\"} or token.tag_ == \"MD\":\n",
    "                verbs.append(token)\n",
    "    verb_total = len(verbs)\n",
    "\n",
    "    present_count = 0\n",
    "    past_count = 0\n",
    "    future_count = 0\n",
    "    for token in verbs:\n",
    "        if \"Tense=Pres\" in token.morph or token.tag_ in {\"VBP\", \"VBZ\", \"VBG\"}:\n",
    "            present_count += 1\n",
    "        if \"Tense=Past\" in token.morph or token.tag_ in {\"VBD\", \"VBN\"}:\n",
    "            past_count += 1\n",
    "        if token.tag_ == \"MD\" or \"Tense=Fut\" in token.morph:\n",
    "            future_count += 1\n",
    "    tense_ratio_present = present_count / verb_total if verb_total > 0 else 0.0\n",
    "    tense_ratio_past = past_count / verb_total if verb_total > 0 else 0.0\n",
    "    tense_ratio_future = future_count / verb_total if verb_total > 0 else 0.0\n",
    "\n",
    "    # --- embedding similarity to baseline ---\n",
    "    semantic_similarity_drift = 0.0\n",
    "    if baseline_embedding is not None:\n",
    "        try:\n",
    "            emb = sentence_model.encode(transcript_text)\n",
    "            dot = float(np.dot(emb, baseline_embedding))\n",
    "            denom = np.linalg.norm(emb) * np.linalg.norm(baseline_embedding)\n",
    "            similarity = dot / denom\n",
    "            semantic_similarity_drift = 1.0 - similarity\n",
    "        except Exception:\n",
    "            semantic_similarity_drift = 0.0\n",
    "\n",
    "    # --- assemble results ---\n",
    "    features = {\n",
    "        \"speech_speed\": float(speech_speed),  # words per second\n",
    "        \"pauses\": float(num_pauses),  # total number of pauses\n",
    "        \"pause_mean\": float(pause_mean),  # average pause duration\n",
    "        \"pause_var\": float(pause_var),  # variance of pause durations\n",
    "        \"vocab_richness\": float(vocab_richness),  # unique words / total words\n",
    "        \"filler_word_rate\": float(filler_word_rate),  # proportion of filler words\n",
    "        \"lexical_diversity\": float(lexical_diversity),  # lexical diversity score\n",
    "        \"avg_sentence_length\": float(avg_sentence_length),  # words per sentence\n",
    "        #\"avg_parse_depth\": float(avg_parse_depth),  # parse tree depth\n",
    "        \"speech_articulation_rate\": float(speech_articulation_rate),  # syllables per second\n",
    "        #\"coherence_score\": float(coherence_score),  # topic coherence variance\n",
    "        \"repetition_rate\": float(repetition_rate),  # repeated word ratio\n",
    "        \"pronoun_noun_ratio\": float(pronoun_noun_ratio),  # pronouns to nouns\n",
    "        \"avg_dependency_length\": float(avg_dependency_length),  # dependency distance\n",
    "        \"tense_ratio_present\": float(tense_ratio_present),  # share of present tense verbs\n",
    "        \"tense_ratio_past\": float(tense_ratio_past),  # share of past tense verbs\n",
    "        \"tense_ratio_future\": float(tense_ratio_future),  # share of future tense verbs\n",
    "        \"semantic_similarity_drift\": float(semantic_similarity_drift),  # difference from baseline\n",
    "    }\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb7f90",
   "metadata": {},
   "source": [
    "## Data loading helpersJust simple wrappers to stash daily results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d88ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_whisper_outputs(json_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load Whisper transcript segments from a JSON file.\"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data.get('segments', [])\n",
    "\n",
    "def update_patient_day_from_json(patient_id: str, day: int, json_path: str, baseline_emb: Optional[np.ndarray] = None):\n",
    "    segments = load_whisper_outputs(json_path)\n",
    "    transcript = ' '.join(seg.get('text', '') for seg in segments)\n",
    "    duration = segments[-1]['end'] if segments else 0\n",
    "    features = compute_features(transcript, duration, segments, baseline_emb)\n",
    "    if patient_id not in history:\n",
    "        history[patient_id] = []\n",
    "    history[patient_id].append({'day': day, **features})\n",
    "    if patient_id not in baseline:\n",
    "        baseline[patient_id] = features\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae12449",
   "metadata": {},
   "source": "## plot_trends Super basic plots so we can see what's up.\n"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b9f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trends(patient_id: str):\n",
    "    df = pd.DataFrame(history.get(patient_id, []))\n",
    "    if df.empty:\n",
    "        print('No history for', patient_id)\n",
    "        return\n",
    "    df.set_index('day', inplace=True)\n",
    "    df.plot(subplots=True, figsize=(12, 18), marker='o')\n",
    "    plt.suptitle(f'Patient {patient_id} - Speech Feature Trends')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197f4b1",
   "metadata": {},
   "source": [
    "## generate_explainable_report    Prints some diffs vs baseline. monkeyp atch but good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bc58370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explainable_report(patient_id: str):\n",
    "    if patient_id not in baseline or patient_id not in history:\n",
    "        print('No data for', patient_id)\n",
    "        return\n",
    "    latest = history[patient_id][-1]\n",
    "    base = baseline[patient_id]\n",
    "    print(f'Patient {patient_id} - Day {latest[\"day\"]}')\n",
    "    for k, v in latest.items():\n",
    "        if k == 'day':\n",
    "            continue\n",
    "        change = ((v - base[k]) / base[k] * 100) if base[k] else 0\n",
    "        print(f'{k}: {v:.3f} (change {change:+.1f}%)')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe3667",
   "metadata": {},
   "source": [
    "## Mregression all the way. Also threw in a bootstrap helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf85a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train_multi_task_model(df: pd.DataFrame):\n",
    "    feature_cols = [c for c in df.columns if c not in ['MMSE', 'MoCA', 'CDR', 'day']]\n",
    "    X = df[feature_cols]\n",
    "    y = df[['MMSE', 'MoCA', 'CDR']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    print(f'Model MSE: {mse:.2f}')\n",
    "    return model\n",
    "\n",
    "def bootstrap_confidence_interval(data: np.ndarray, iterations: int = 1000, alpha: float = 0.05):\n",
    "    samples = []\n",
    "    n = len(data)\n",
    "    for _ in range(iterations):\n",
    "        resample = np.random.choice(data, size=n, replace=True)\n",
    "        samples.append(np.mean(resample))\n",
    "    lower = np.percentile(samples, 100 * (alpha / 2))\n",
    "    upper = np.percentile(samples, 100 * (1 - alpha / 2))\n",
    "    return lower, upper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da077d8c",
   "metadata": {},
   "source": [
    "## Example run \n",
    "Shows the flow from fake transcripts to predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ff76b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      4\u001B[39m text = \u001B[33m'\u001B[39m\u001B[33mThis is a short example transcript with uh pauses and filler words.\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m      5\u001B[39m duration = \u001B[32m30.0\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m compute = \u001B[43mcompute_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mduration\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m patient \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m history:\n\u001B[32m      8\u001B[39m     history[patient] = []\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 31\u001B[39m, in \u001B[36mcompute_features\u001B[39m\u001B[34m(transcript_text, duration_sec, segments, baseline_embedding)\u001B[39m\n\u001B[32m     28\u001B[39m speech_speed = total_words / duration_sec \u001B[38;5;28;01mif\u001B[39;00m duration_sec > \u001B[32m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[32m0.0\u001B[39m\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m# --- pause statistics ---\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m marker_pauses = \u001B[38;5;28mlen\u001B[39m(\u001B[43mre\u001B[49m.findall(\u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\\\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\\\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\\\u001B[39m\u001B[33m.|<pause>\u001B[39m\u001B[33m\"\u001B[39m, transcript_text))\n\u001B[32m     32\u001B[39m gap_durations = []\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(segments)):\n",
      "\u001B[31mNameError\u001B[39m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "# Simulated example data\n",
    "patient = 'P001'\n",
    "for day in range(1, 4):\n",
    "    text = 'This is a short example transcript with uh pauses and filler words.'\n",
    "    duration = 30.0\n",
    "    compute = compute_features(text, duration)\n",
    "    if patient not in history:\n",
    "        history[patient] = []\n",
    "        baseline[patient] = compute\n",
    "    history[patient].append({'day': day, **compute})\n",
    "\n",
    "df = pd.DataFrame(history[patient])\n",
    "df['MMSE'] = 30 - df['day'] * 0.5\n",
    "df['MoCA'] = 28 - df['day'] * 0.4\n",
    "df['CDR'] = 0.5 + df['day'] * 0.05\n",
    "\n",
    "model = train_multi_task_model(df)\n",
    "plot_trends(patient)\n",
    "generate_explainable_report(patient)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
